# SeeIt

Inclusive Android app with two core capabilities:  

1. âœ‹ **ASL Mode** â€“ Speech â†’ Text â†’ ASL Video  
2. ğŸ‘ï¸ **Object Detection Mode** â€“ Camera â†’ Detect â†’ Speak  

---

## âœ‹ 1. ASL Mode  

### What It Does  
- ğŸ™ï¸ Listens from mic â†’ converts **speech to text**  
- ğŸ”¤ Maps text to **ASL signs**  
- â–¶ï¸ Fetches ASL videos from the web and **plays them in-app**  

### Key Features  
- âš¡ Partial results (near word-by-word feel)  
- ğŸ¯ Candidate ranking (choose the best sign/video)  
- ğŸ”„ Caching + retry/backoff to reduce lag  

### Demo  

https://github.com/user-attachments/assets/c31b4838-6ffb-413a-a6cd-38d3aea3a1af

## ğŸ‘ï¸ 2. Object Detection Mode  

### What It Does  
- ğŸ“· Uses **camera** to detect objects in real time  
- ğŸ—£ï¸ Speaks object names via **Text-to-Speech (TTS)**  
- ğŸ·ï¸ Optionally shows detected labels on screen  

### Key Features  
- âš¡ Real-time detection (CameraX + ML Kit/TFLite)  
- ğŸ”• Debounced announcements (avoid spam)  
- ğŸ“Š Confidence threshold + label coalescing  
- ğŸ“¦ Works **offline** using local models  

### Demo  
https://github.com/user-attachments/assets/88cdca3c-0b67-4257-b9bf-bb1751122672





